[2024-02-05T07:39:04.616+0000] {taskinstance.py:1171} INFO - Dependencies all met for <TaskInstance: user_processing.inserting_data manual__2024-02-05T07:39:02.374645+00:00 [queued]>
[2024-02-05T07:39:04.631+0000] {taskinstance.py:1171} INFO - Dependencies all met for <TaskInstance: user_processing.inserting_data manual__2024-02-05T07:39:02.374645+00:00 [queued]>
[2024-02-05T07:39:04.632+0000] {taskinstance.py:1368} INFO - 
--------------------------------------------------------------------------------
[2024-02-05T07:39:04.632+0000] {taskinstance.py:1369} INFO - Starting attempt 1 of 1
[2024-02-05T07:39:04.633+0000] {taskinstance.py:1370} INFO - 
--------------------------------------------------------------------------------
[2024-02-05T07:39:04.647+0000] {taskinstance.py:1389} INFO - Executing <Task(PostgresOperator): inserting_data> on 2024-02-05 07:39:02.374645+00:00
[2024-02-05T07:39:04.654+0000] {standard_task_runner.py:52} INFO - Started process 78535 to run task
[2024-02-05T07:39:04.657+0000] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'user_processing', 'inserting_data', 'manual__2024-02-05T07:39:02.374645+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/create_table.py', '--cfg-path', '/tmp/tmpoam_x_u7', '--error-file', '/tmp/tmph7oz1lex']
[2024-02-05T07:39:04.659+0000] {standard_task_runner.py:80} INFO - Job 23: Subtask inserting_data
[2024-02-05T07:39:04.724+0000] {task_command.py:371} INFO - Running <TaskInstance: user_processing.inserting_data manual__2024-02-05T07:39:02.374645+00:00 [running]> on host fe2863c78e2f
[2024-02-05T07:39:04.809+0000] {taskinstance.py:1583} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=user_processing
AIRFLOW_CTX_TASK_ID=inserting_data
AIRFLOW_CTX_EXECUTION_DATE=2024-02-05T07:39:02.374645+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-02-05T07:39:02.374645+00:00
[2024-02-05T07:39:04.820+0000] {base.py:68} INFO - Using connection ID '***_postgres' for task execution.
[2024-02-05T07:39:04.824+0000] {sql.py:315} INFO - Running statement: INSERT INTO users (firstname, lastname, country, username, password, email)
            VALUES 
                ('John', 'Doe', 'USA', 'johndoe', 'password123', 'john.doe@example.com'),
                ('Jane', 'Smith', 'Canada', 'janesmith', 'password456', 'jane.smith@example.com'), parameters: None
[2024-02-05T07:39:04.826+0000] {taskinstance.py:1902} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 295, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 320, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "users_pkey"
DETAIL:  Key (email)=(john.doe@example.com) already exists.

[2024-02-05T07:39:04.836+0000] {taskinstance.py:1412} INFO - Marking task as FAILED. dag_id=user_processing, task_id=inserting_data, execution_date=20240205T073902, start_date=20240205T073904, end_date=20240205T073904
[2024-02-05T07:39:04.847+0000] {standard_task_runner.py:97} ERROR - Failed to execute job 23 for task inserting_data (duplicate key value violates unique constraint "users_pkey"
DETAIL:  Key (email)=(john.doe@example.com) already exists.
; 78535)
[2024-02-05T07:39:04.873+0000] {local_task_job.py:156} INFO - Task exited with return code 1
[2024-02-05T07:39:04.909+0000] {local_task_job.py:279} INFO - 0 downstream tasks scheduled from follow-on schedule check
